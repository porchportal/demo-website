{
  "title": "Left Ventricular Ejection Fraction (LVEF)",
  "titleMobile": "LVEF",
  "loading": "Loading LVEF visualization...",
  "subtitle": "Ultrasound-Based Echocardiographic Analysis using CoReEcho with Grad-CAM–Guided Optimization",
  "description": "Left Ventricular Ejection Fraction (LVEF) is a measurement of the percentage of blood leaving your heart each time it contracts.",
  "form": {
    "heading": "Calculate LVEF",
    "edvLabel": "End-Diastolic Volume (mL):",
    "edvPlaceholder": "Enter EDV",
    "esvLabel": "End-Systolic Volume (mL):",
    "esvPlaceholder": "Enter ESV",
    "calculateButton": "Calculate LVEF"
  },
  "ranges": {
    "heading": "LVEF Ranges",
    "description": "The American College of Cardiology classifies LVEF into the following categories (Kosaraju et al., 2023):",
    "categories": [
      {
        "label": "Hyperdynamic",
        "value": ">70%",
        "description": "LVEF greater than 70%",
        "color": "#10b981"
      },
      {
        "label": "Normal",
        "value": "50-70%",
        "description": "LVEF 50% to 70%",
        "color": "#22c55e"
      },
      {
        "label": "Mild Dysfunction",
        "value": "40-49%",
        "description": "LVEF 40% to 49%",
        "color": "#f59e0b"
      },
      {
        "label": "Moderate Dysfunction",
        "value": "30-39%",
        "description": "LVEF 30% to 39%",
        "color": "#f97316"
      },
      {
        "label": "Severe Dysfunction",
        "value": "<30%",
        "description": "LVEF less than 30%",
        "color": "#ef4444"
      }
    ]
  },
  "images": {
    "heartModel": "/assets/image_medical/lvef_3d_.png",
    "coReEcho": "/assets/image_medical/CoReEcho.png",
    "gradCam": "/assets/image_medical/GradCam.png",
    "tableExperimental": "/assets/image_medical/table_experimental.png",
    "formula": "/assets/image_medical/formular.png",
    "dataDemoImage": "/assets/image_medical/data_demo_image.png",
    "dataDemo1Gif": "/assets/image_medical/data_demo_1.gif",
    "dataDemo2Gif": "/assets/image_medical/data_demo_2.gif",
    "importantFrame": "/assets/image_medical/important_frame.png",
    "camAnalysisDemo": "/assets/image_medical/cam_analysis_demo_3.gif"
  },
  "sections": {
    "objective": {
      "title": "Objective",
      "content": "To develop a deep learning framework capable of estimating Left Ventricular Ejection Fraction (LVEF) from echocardiography, while utilizing Grad-CAM visualization not only for interpretability but also to optimize model attention—guiding the AI toward clinically relevant ventricular regions for more reliable and explainable cardiac assessment."
    },
    "dataset": {
      "title": "Dataset Overview",
      "intro": "The dataset used in this study comprises echocardiographic video sequences of the heart in the apical four-chamber (A4C) view, covering complete cardiac cycles from end-diastolic (EDV) to end-systolic (ESV) phases. Each video was manually annotated by experts to identify the ventricular boundaries at both phases, enabling the calculation of Left Ventricular Ejection Fraction (LVEF) as:",
      "figureDescription": "Figure 2 illustrates a representative example from the dataset.",
      "panels": [
        "The left panel shows the end-diastolic frame (EDV) — the point of maximal ventricular filling before contraction.",
        "The right panel shows the end-systolic frame (ESV) — the moment of maximal contraction when the ventricle is smallest."
      ],
      "overlay": "The red overlay highlights the segmented left ventricular cavity, which is used to calculate ventricular volume and determine the LVEF.",
      "waveform": "The graph below the ultrasound frames corresponds to the cardiac cycle waveform, where the EDV and ESV points are marked to indicate how volume changes dynamically throughout the heartbeat.",
      "providesTitle": "This dataset provides:",
      "provides": [
        "Frame-level temporal information (capturing heart motion over time),",
        "Quantitative volume annotations (EDV, ESV, LVEF) for supervised regression, and",
        "Visual interpretability through segmentation masks and waveform alignment."
      ],
      "conclusion": "Together, these elements support both quantitative evaluation of cardiac function and qualitative analysis of model attention when using Grad-CAM visualization."
    },
    "overview": {
      "title": "CoReEcho Framework Overview",
      "subtitle": "CoReEcho (Context-Relation Echocardiography Network) is a two-stage learning framework designed for robust and generalizable cardiac function estimation.",
      "stage1": {
        "title": "Stage 1 — Representation Learning",
        "points": [
          "Echocardiogram clips are augmented and sampled with different frame counts (FC) and temporal strides (T).",
          "The Feature Extractor (Fₑ) encodes spatiotemporal features.",
          "A Shallow MLP regressor (Fᵣ) predicts LVEF under a combined relational consistency loss (Lₙᶜ) and regression loss (L₁)."
        ]
      },
      "stage2": {
        "title": "Stage 2 — Fine-tuning with Weight Transfer",
        "points": [
          "The pretrained Fₑ is frozen and reused.",
          "The Fᵣ regressor is fine-tuned for improved performance.",
          "Evaluation conducted on various FC–T configurations."
        ]
      },
      "benefit": "This two-step process enhances feature robustness while reducing overfitting on limited cardiac datasets."
    },
    "gradcam": {
      "title": "CAM-Based Visual Explanation and Model Optimization",
      "intro": "To enhance model interpretability and optimize attention mechanisms, we applied Finer-CAM along with multiple Class Activation Mapping (CAM) techniques from the comprehensive pytorch-grad-cam library. This suite of methods—including Grad-CAM, Layer-CAM, FullGrad, and Finer-CAM—enables fine-grained visualization of neural network decision-making processes across different architectural depths and abstraction levels.",
      "methodology": {
        "title": "Implementation and Modifications",
        "description": "We modified the CAM pipeline to support the fine-tuned UniFormer spatiotemporal feature extractor used in CoReEcho. Layer-specific activation mappings were extracted at multiple network depths to identify which cardiac structures contribute most significantly to LVEF predictions. Finer-CAM, in particular, revealed subtle anatomical features through differential activation analysis, spotting differences that distinguish normal from dysfunctional myocardial regions."
      },
      "frameSelection": {
        "title": "Important Frame Extraction Strategy",
        "description": "Following CAM analysis, we developed an automated important frame extraction procedure to optimize CoReEcho model configuration. Rather than processing entire echocardiographic sequences uniformly, frames exhibiting high activation magnitudes in diagnostically relevant regions—particularly the endocardial border during systolic contraction—were prioritized. This frame selection strategy reduced computational overhead while preserving critical temporal information necessary for accurate LVEF estimation. Figure X demonstrates representative examples of selected important frames based on peak CAM responses in the left ventricular cavity."
      },
      "visualization": {
        "title": "Dynamic CAM Visualization",
        "description": "To validate model attention throughout the cardiac cycle, we generated temporal CAM heatmap sequences overlaid on echocardiographic videos (presented as GIF animations). These visualizations confirm that the optimized model consistently focuses on physiologically meaningful structures—the left ventricular walls and septum—during both diastolic filling and systolic ejection phases. Video-based CAM analysis further reveals that attention patterns dynamically track myocardial motion, aligning with known biomechanical behavior."
      },
      "outcome": "The integration of advanced CAM techniques not only improved interpretability but also provided quantitative feedback for model refinement. By identifying and emphasizing diagnostically salient frames, the CAM-guided optimization yielded enhanced LVEF prediction accuracy and stronger correlation with expert cardiologist assessments, as demonstrated in the experimental results."
    },
    "results": {
      "title": "Experimental Results",
      "content": "The experimental evaluation compared multiple model configurations to assess the impact of CAM-based optimization on AI-assisted echocardiography. The blue-highlighted configuration in the results table represents the baseline setup, corresponding to the original CoReEcho model design. This configuration serves as a reference point for subsequent improvements.\n\nAcross all tested configurations, models optimized with CAM analysis feedback—incorporating Grad-CAM, Layer-CAM, FullGrad, and Finer-CAM—consistently demonstrated superior interpretability and quantitative performance. By integrating advanced CAM techniques during model refinement, the system gained enhanced spatial awareness of diagnostically relevant cardiac regions, allowing more precise feature extraction from the left ventricular area and improved attention to physiologically meaningful structures.\n\nAs shown in the green-highlighted row, the CAM-optimized configuration achieved the highest performance among all tested setups. It demonstrated improved Left Ventricular Ejection Fraction (LVEF) estimation accuracy, enhanced localization of myocardial motion patterns, and reduced prediction variance compared to the baseline. The integration of important frame extraction—guided by peak CAM activation responses—further contributed to computational efficiency without sacrificing predictive performance.\n\nQualitatively, multi-method CAM heatmaps confirmed that the optimized model consistently focuses on clinically meaningful structures—particularly the endocardial border, interventricular septum, and left ventricular walls—during both systolic contraction and diastolic filling phases. Supporting evidence is provided through dynamic CAM video visualizations, which clearly illustrate attention progression throughout complete cardiac cycles. These visual results demonstrate that the CAM-guided model dynamically tracks key myocardial motion patterns more effectively than the baseline, with attention patterns aligning closely with known cardiac biomechanics.\n\nIn summary, the integration of advanced CAM analysis techniques not only enhances model interpretability through fine-grained visualization but also yields measurable gains in predictive accuracy and clinical alignment. The CAM-guided optimization framework—combining multiple visualization methods with intelligent frame selection—represents a promising pathway for trustworthy, explainable, and clinically validated AI-assisted ultrasound analysis."
    },
    "impact": {
      "title": "Clinical & Research Impact",
      "points": [
        "🩺 Clinical Insight: Advanced CAM visualizations improve physician trust and help validate model reasoning through multi-method interpretability.",
        "⚙️ Technical Innovation: CAM analysis integration transforms explainability into an optimization feedback loop, guiding attention toward clinically relevant cardiac structures.",
        "🌍 Scalability: Suitable for real-time ultrasound analysis and deployment in hospitals or telehealth systems with intelligent frame selection for computational efficiency."
      ]
    },
    "references": {
      "title": "References",
      "mainMethods": {
        "title": "Main Methods",
        "items": [
          {
            "name": "CoReEcho (16 Sep 2024)",
            "description": "Continuous Representation Learning for 2D+time Echocardiography Analysis",
            "paper": "https://arxiv.org/abs/2403.10164",
            "github": "https://github.com/BioMedIA-MBZUAI/CoReEcho"
          },
          {
            "name": "UniFormer (8 Feb 2022)",
            "description": "UNIFIED TRANSFORMER FOR EFFICIENT SPATIOTEMPORAL REPRESENTATION LEARNING",
            "paper": "https://arxiv.org/pdf/2201.04676",
            "github": "https://github.com/Sense-X/UniFormer"
          },
          {
            "name": "Grad-CAM (3 Dec 2019)",
            "description": "Visual Explanations from Deep Networks via Gradient-based Localization",
            "paper": "https://arxiv.org/pdf/1610.02391",
            "github": "https://github.com/ramprs/grad-cam/"
          },
          {
            "name": "Additional GradCAM model",
            "description": "Advanced Explainable AI for computer vision",
            "github": "https://github.com/jacobgil/pytorch-grad-cam?tab=readme-ov-file"
          },
          {
            "name": "Finer-CAM (2025)",
            "description": "Spotting the Difference Reveals Finer Details for Visual Explanation",
            "paper": "https://arxiv.org/abs/2501.11309",
            "github": "https://github.com/Imageomics/Finer-CAM"
          }
        ]
      },
      "additional": {
        "title": "Additional",
        "items": [
          {
            "description": "The American College of Cardiology classifies LVEF into the following categories (Kosaraju et al., 2023)",
            "link": "https://www.nursingcenter.com/blogs-plus/blogs/blogs-post?identifier=How-to-Calculate-Ejection-Fraction#/post/How-to-Calculate-Ejection-Fraction",
            "source": "NursingCenter"
          },
          {
            "description": "Global Public Health Burden of Heart Failure (27 Jul 2023): An Updated Review",
            "link": "https://pmc.ncbi.nlm.nih.gov/articles/PMC10398425/",
            "source": "PubMed Central (PMC)"
          }
        ]
      }
    }
  }
}
